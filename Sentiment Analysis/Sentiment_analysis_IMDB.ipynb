{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iee7RD_NZaFv"
   },
   "source": [
    "# <font color='black'>Sentiment analysis</font>\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxG54SMuZaF0"
   },
   "source": [
    "### Sarah Sheikh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZR9GGGuZaF1"
   },
   "source": [
    "In this question, you will implement a Naive Bayes model to predict the class of comments of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9APIoUgZaF2"
   },
   "source": [
    "## Naive Bayes model on IMDB dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt3V_RsxZaF2"
   },
   "source": [
    "#### A.Import needed libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sIEPu6cZaF3"
   },
   "source": [
    "Import any other libraries that you will need in your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CyQli0VgZaF3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import re \n",
    "\n",
    "## your code to import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OcW93XpZaF5"
   },
   "source": [
    "#### B.Load dataset and create matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYltH13SLPec",
    "outputId": "f9ff50bf-beff-4faa-a16d-5fda454e3d87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: wget: command not found\n"
     ]
    }
   ],
   "source": [
    "# dataset obtained from https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "#!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.74 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-data-sets/134715/320111/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20220326%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220326T130213Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=660fcaa841d8db84f25e270e4f68323405e8cb3c07fccb1ca8bf36d8bdd36813cfcd65fd3ee9e53a704d11054ccfcc4e06397ecf42309fafc564cfc1a0ef9a90302106dbc98f62a0406a42ef43539daf444cb85552187ee8c3cb9a0130b4e32e68700fdd91f5885228680243b9757adc754fc9364953af51a0cb52b3858d011c4019af589891adcae4b96f5d586b5509cb7dd9e8875a1d21118179c8f8491ee0f67bfcb6760dd288d993c0687ea80ca54b8d6b413ebc086c5e71995d6a72857a047afb60466b5805118d8092855a556addb3a51b98c05cb214aba3f95cc41d3547b1fc9d4ae1d08c2053ca9936fab8a713eb7b037bdf367dc3138aeb66db7254\" -c -O 'archive.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vvxQixhLYfD",
    "outputId": "6b39337b-a93e-4cf4-ec82-b72d7548409a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open archive.zip, archive.zip.zip or archive.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "#!unzip archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pcVd_WeYL7sx"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "!mkdir train\n",
    "!mkdir test\n",
    "!mkdir train/positive\n",
    "!mkdir train/negative\n",
    "!mkdir test/positive\n",
    "!mkdir test/negative\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGlHp8cJLeT2",
    "outputId": "cd65e93d-e712-44a2-b0f2-cd120cbfccea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOADING DATASET INTO PANDAS DATAFRAME\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jKXVphLsNKQo",
    "outputId": "4e6462d3-dbc9-4c53-9ffe-08cbb19b1159"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hu92HONlMy2A",
    "outputId": "afd483d7-6c81-4e26-936f-d291e9e6fe7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000,) (6000,)\n"
     ]
    }
   ],
   "source": [
    "# Seperating positive and negative labelled data\n",
    "positive = df[df[\"sentiment\"]==\"positive\"]['review'][:6000] # taking 6k points \n",
    "negative = df[df[\"sentiment\"]==\"negative\"]['review'][:6000]\n",
    "print(positive.shape,negative.shape)\n",
    "# splitting train and test data in a ratio of 70:30  \n",
    "ptrain,ptest = train_test_split(positive,train_size=0.7,test_size=0.3)\n",
    "ntrain,ntest = train_test_split(negative,train_size=0.7,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HdBVKDskgWca"
   },
   "outputs": [],
   "source": [
    "# for saving data into corresponding path\n",
    "def save(f_name,data):\n",
    "  with open(f_name,\"w\",encoding=\"utf8\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UoQ1iHTpfPs0"
   },
   "outputs": [],
   "source": [
    "# saving data to corresponding folders\n",
    "for i,x in enumerate(ptrain.values):\n",
    "  save(f\"train/positive/{i}.txt\",x)\n",
    "for i,x in enumerate(ptest.values):\n",
    "  save(f\"test/positive/{i}.txt\",x)\n",
    "for i,x in enumerate(ntrain.values):\n",
    "  save(f\"train/negative/{i}.txt\",x)\n",
    "for i,x in enumerate(ntest.values):\n",
    "  save(f\"test/negative/{i}.txt\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DoPULA6Qo31m"
   },
   "outputs": [],
   "source": [
    "del positive , negative , ptrain , ptest , ntrain, ntest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mmm8I5hTZaF6"
   },
   "source": [
    "Don't change this part of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e4nXWX7tZaF7"
   },
   "outputs": [],
   "source": [
    "\n",
    "stop_words = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\n",
    "            \"an\",\"and\",\"any\",\"are\",\"arent\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\n",
    "            \"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"cant\",\"cannot\",\"could\",\"couldnt\",\n",
    "            \"did\",\"didnt\",\"do\",\"does\",\"doesnt\",\"doing\",\"dont\",\"down\",\"during\",\"each\",\"few\",\n",
    "            \"for\",\"from\",\"further\",\"had\",\"hadnt\",\"has\",\"hasnt\",\"have\",\"havent\",\"having\",\"he\",\n",
    "            \"hed\",\"hell\",\"he\",\"her\",\"here\",\"here\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\n",
    "            \"how\",\"hows\",\"i\",\"id\",\"ill\",\"i\",\"ie\",\"if\",\"in\",\"into\",\"is\",\"isnt\",\"it\",\"it\",\n",
    "            \"its\",\"itself\",\"let\",\"me\",\"more\",\"most\",\"mustnt\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\n",
    "            \"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\n",
    "            \"over\",\"own\",\"same\",\"shant\",\"she\",\"shed\",\"shell\",\"she\",\"should\",\"shouldnt\",\n",
    "            \"so\",\"some\",\"such\",\"than\",\"that\",\"that\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\n",
    "            \"then\",\"there\",\"there\",\"these\",\"they\",\"theyd\",\"theyll\",\"theyre\",\"theye\",\"this\",\n",
    "            \"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"wasnt\",\"we\",\"wed\",\n",
    "            \"well\",\"were\",\"wee\",\"were\",\"werent\",\"what\",\"what\",\"when\",\"when\",\"where\",\n",
    "            \"where\",\"which\",\"while\",\"who\",\"who\",\"whom\",\"why\",\"why\",\"with\",\"wont\",\"would\",\n",
    "            \"wouldnt\",\"you\",\"youd\",\"youll\",\"youre\",\"youve\",\"your\",\"yours\",\"yourself\",\"yourselves\",\n",
    "            \"nt\",\"d\",\"ll\",\"re\",\"ve\",\"r\",\"t\",\"nd\",\"s\",\"br\"]\n",
    "\n",
    "def get_data():\n",
    "    train_positive = glob.glob('train/positive/*') # accessing data from the folder\n",
    "    train_negative = glob.glob('train/negative/*')\n",
    "    test_positive = glob.glob('test/positive/*')\n",
    "    test_negative = glob.glob('test/negative/*')\n",
    "    x_train = []     # initializing\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    # reading the reviews data with UTF-8 encoding to train and test data\n",
    "    for file in train_positive:\n",
    "        f = open(file, 'r', encoding=\"utf8\")\n",
    "        x_train.append(f.read())\n",
    "        y_train.append(1) # appending label\n",
    "        f.close()\n",
    "    for file in train_negative:\n",
    "        f = open(file, 'r', encoding=\"utf8\")\n",
    "        x_train.append(f.read())\n",
    "        y_train.append(0)\n",
    "        f.close()\n",
    "    for file in test_positive:\n",
    "        f = open(file, 'r', encoding=\"utf8\")\n",
    "        x_test.append(f.read())\n",
    "        y_test.append(1)\n",
    "        f.close()\n",
    "    for file in test_negative:\n",
    "        f = open(file, 'r', encoding=\"utf8\")\n",
    "        x_test.append(f.read())\n",
    "        y_test.append(0)\n",
    "        f.close()\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def clean_text(x_train, x_test):\n",
    "   # preprocessing the text by removing numbers and special charecters\n",
    "    for index, text in enumerate(x_train):\n",
    "        x_train[index] = ' '.join((re.sub(\"[^a-zA-Z\\s]\", \"\", text)).lower().split()) # remove spl/numerical charecters\n",
    "    for index, text in enumerate(x_test):\n",
    "        x_test[index] = ' '.join((re.sub(\"[^a-zA-Z\\s]\", \"\", text)).lower().split())\n",
    "    return x_train, x_test\n",
    "\n",
    "# Bag-of-words\n",
    "def get_whole_words(x_train, x_test, stop_words):\n",
    "    # storing all unique words in dictionary\n",
    "    whole_words = dict() # initilizing dictionary\n",
    "    for text in x_train:\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            if word not in stop_words:\n",
    "                if word not in whole_words.keys():\n",
    "                    whole_words[word] = len(whole_words) # assigning the len(dictionary) to each unique word\n",
    "    for text in x_test:\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            if word not in stop_words:\n",
    "                if word not in whole_words.keys():\n",
    "                    whole_words[word] = len(whole_words)\n",
    "    return whole_words\n",
    "\n",
    "\n",
    "def get_matrix_of_x(x_train, x_test, words): # building feature matrix for x\n",
    "    train_matrix = np.zeros((len(x_train), len(words)), dtype='uint8') # matrix initialization\n",
    "    test_matrix = np.zeros((len(x_test), len(words)), dtype='uint8')\n",
    "    for index, text in enumerate(x_train):\n",
    "        text_words = text.split()\n",
    "        for word in text_words:\n",
    "            if word not in stop_words:\n",
    "                train_matrix[index, words[word]] += 1\n",
    "    for index, text in enumerate(x_test):\n",
    "        text_words = text.split()\n",
    "        for word in text_words:\n",
    "            if word not in stop_words:\n",
    "                test_matrix[index, words[word]] += 1\n",
    "            \n",
    "    return train_matrix, test_matrix\n",
    "\n",
    "x_train, y_train, x_test, y_test = get_data()\n",
    "x_train, x_test = clean_text(x_train, x_test)\n",
    "words = get_whole_words(x_train, x_test, stop_words)\n",
    "train_matrix, test_matrix = get_matrix_of_x(x_train, x_test, words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "y7Y11YffKdTa"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hq/7g25cm9j3zq970jd1s_dj4xc0000gn/T/ipykernel_18859/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZcZ5TxnvW0X",
    "outputId": "02195751-4273-4bd5-af51-aff593bac030"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 3, ..., 0, 0, 0],\n",
       "       [0, 0, 4, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5JAtTw33kZbc"
   },
   "outputs": [],
   "source": [
    "del x_train \n",
    "del x_test\n",
    "del words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88liSDEbZaF9"
   },
   "source": [
    "#### C.Find the best smoothing value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqpmWagcZaF9"
   },
   "source": [
    "Find the best smoothing value for your dataset by using K-fold cross-validation(K=10) for 5 equidistant smoothing values in the (0,1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-0rPNzUZaF-",
    "outputId": "21f8c339-3e61-43ca-cbf7-1bc77dea8581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy percentage for the above folds with alpha 0.001 is 0.7857142857142857\n",
      "mean accuracy percentage for the above folds with alpha 0.01 is 0.8054761904761906\n",
      "mean accuracy percentage for the above folds with alpha 0.1 is 0.8289285714285715\n",
      "mean accuracy percentage for the above folds with alpha 1 is 0.8438095238095238\n",
      "mean accuracy percentage for the above folds with alpha 10 is 0.845\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# your code to find the best smoothing value\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "smoothing_val = {}\n",
    "# selecting hyper-parameter alpha for 5 values\n",
    "alpha = [0.001,0.01,0.1,1,10] \n",
    "for a in alpha:\n",
    "  clf = MultinomialNB(alpha=a)\n",
    "  # using k-fold cross validation with k = 10\n",
    "  scores = cross_val_score(clf, train_matrix, y_train, cv=10,scoring='accuracy')\n",
    "  smoothing_val.update({scores.mean():clf})\n",
    "  print(f\"mean accuracy percentage for the above folds with alpha {a} is {scores.mean()}\")\n",
    "best_smoothing_val = max(smoothing_val.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ik9csSe6ZaF-"
   },
   "source": [
    "#### D.Model Naive Bayes and predict test data labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmVsDVcYZaF_"
   },
   "source": [
    "Model Naive Bayes by using the best smoothing value that you have found in the previous part. Report the train and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7eQytDFZaF_",
    "outputId": "5325d265-ab8b-45d9-efc1-f96604d5d5d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the sentiment analysis model is 0.8441666666666666 %\n",
      "----------\n",
      "Confusion matrix for above model performance for test data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1557,  243],\n",
       "       [ 318, 1482]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code to model naive bayes\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "model = smoothing_val[best_smoothing_val]\n",
    "model.fit(train_matrix,y_train)\n",
    "train_pred = model.predict(train_matrix)\n",
    "test_pred = model.predict(test_matrix)\n",
    "\n",
    "# your code to report the train and test accuracy\n",
    "train_metric= accuracy_score(y_train,train_pred)\n",
    "test_metric= accuracy_score(y_test,test_pred)\n",
    "print(f\"The accuracy of the sentiment analysis model is {test_metric} %\")\n",
    "print(\"-\"*10)\n",
    "print(\"Confusion matrix for above model performance for test data\")\n",
    "confusion_matrix(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zn3YznOHZBs4",
    "outputId": "6e5618ce-a2a4-43b2-9273-533f1cae4e96"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hq/7g25cm9j3zq970jd1s_dj4xc0000gn/T/ipykernel_24950/624127789.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_train,train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2MKAk9sJMKQ"
   },
   "outputs": [],
   "source": [
    "# saving the transformation matrix (model weights)\n",
    "import pickle\n",
    "\n",
    "with open('model_pkl', 'wb') as files:\n",
    "    pickle.dump(model, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1qYybMGutvG"
   },
   "outputs": [],
   "source": [
    "# loading the model\n",
    "with open('model_pkl', 'rb') as files:\n",
    "    pickle.load(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment-analysis-IMDB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
